{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worldview & Ideology Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains examples of how to perform the analysis from \"Aligning Multidimensional Worldviews and Discovering Ideological Differences\" (Milbauer et al., 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_a, source_b = 'subreddit_askmen', 'subreddit_askwomen'\n",
    "with open('./corpus/{}.txt'.format(source_a), encoding='utf-8') as f:\n",
    "    corpus_a = f.readlines()\n",
    "with open('./corpus/{}.txt'.format(source_b), encoding='utf-8') as f:\n",
    "    corpus_b = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the trained embeddings, and quickly examine them to see if they make sense.\n",
    "We are using small text samples (500k tokens), so embeddings may not be very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('republican', 0.6307386159896851)\n",
      "('dem', 0.6165011525154114)\n",
      "('democrats', 0.6043610572814941)\n",
      "('democratic', 0.5978788137435913)\n",
      "('dems', 0.49818018078804016)\n",
      "('liberal', 0.48974037170410156)\n",
      "('candidate', 0.4867892265319824)\n",
      "('party', 0.4780939519405365)\n",
      "('republicans', 0.477538526058197)\n",
      "('progressive', 0.4756127595901489)\n",
      "\n",
      "('dem', 0.6980773210525513)\n",
      "('republican', 0.6605644226074219)\n",
      "('democratic', 0.6189409494400024)\n",
      "('democrats', 0.6140726804733276)\n",
      "('party', 0.6009922623634338)\n",
      "('dems', 0.48170965909957886)\n",
      "('liberal', 0.4369395971298218)\n",
      "('leftist', 0.42886313796043396)\n",
      "('left', 0.4251934587955475)\n",
      "('candidates', 0.4231654405593872)\n"
     ]
    }
   ],
   "source": [
    "model_a = Word2Vec.load('models/politics.word2vec.model')\n",
    "model_b = Word2Vec.load('models/the_donald.word2vec.model')\n",
    "# pretrained on more data\n",
    "# model_a = Word2Vec.load('models/politics.big.model')\n",
    "# model_b = Word2Vec.load('models/the_donald.big.model')\n",
    "\n",
    "posWords = ['democrat']\n",
    "negWords = []\n",
    "for x in model_a.wv.most_similar(positive=posWords, negative=negWords):\n",
    "    print(x)\n",
    "print()\n",
    "for x in model_b.wv.most_similar(positive=posWords, negative=negWords):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('addiction', 0.674181342124939)\n",
      "('watching', 0.5972264409065247)\n",
      "('watch', 0.5872642993927002)\n",
      "('watched', 0.5676982402801514)\n",
      "('modern', 0.561260461807251)\n",
      "('fantasy', 0.5315399765968323)\n",
      "('content', 0.5298962593078613)\n",
      "('argue', 0.5205428600311279)\n",
      "('becomes', 0.5109003186225891)\n",
      "('sexuality', 0.5108972787857056)\n",
      "\n",
      "('creepy', 0.5877805948257446)\n",
      "('attracted', 0.5398934483528137)\n",
      "('pleasure', 0.5357645750045776)\n",
      "('flirting', 0.5247712135314941)\n",
      "('man', 0.5183247327804565)\n",
      "('sexually', 0.5093643665313721)\n",
      "('watching', 0.5009644031524658)\n",
      "('dudes', 0.49731189012527466)\n",
      "('hitting', 0.4970484673976898)\n",
      "('anime', 0.4925317168235779)\n"
     ]
    }
   ],
   "source": [
    "# MY DATASET\n",
    "\n",
    "model_a = Word2Vec.load('data/models/{}.model'.format(source_a))\n",
    "model_b = Word2Vec.load('data/models/{}.model'.format(source_b))\n",
    "# pretrained on more data\n",
    "# model_a = Word2Vec.load('models/politics.big.model')\n",
    "# model_b = Word2Vec.load('models/the_donald.big.model')\n",
    "\n",
    "posWords = ['men', 'porn']\n",
    "negWords = ['women']\n",
    "for x in model_a.wv.most_similar(positive=posWords, negative=negWords):\n",
    "    print(x)\n",
    "print()\n",
    "for x in model_b.wv.most_similar(positive=posWords, negative=negWords):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we find the overlapping vocabulary of the two models, and use this to construct an embedding matrix for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_a = list(set(model_a.wv.vocab.keys()))\n",
    "vocab_b = list(set(model_b.wv.vocab.keys()))\n",
    "\n",
    "shared_vocab = set.intersection(set(vocab_a),\n",
    "                                set(vocab_b))\n",
    "shared_vocab = list(sorted(list(shared_vocab)))\n",
    "combo_vocab = set.union(set(vocab_a),\n",
    "                                set(vocab_b))\n",
    "\n",
    "w2idx = { w:i for i,w in enumerate(shared_vocab) }\n",
    "a2idx = { w:i for i,w in enumerate(vocab_a) }\n",
    "idx2b = { i:w for i,w in enumerate(vocab_b) }\n",
    "\n",
    "mtxA = np.vstack([model_a.wv[w] for w in shared_vocab])\n",
    "mtxB = np.vstack([model_b.wv[w] for w in shared_vocab])\n",
    "mtxA_ = np.vstack([model_a.wv[w] for w in vocab_a])\n",
    "mtxB_ = np.vstack([model_b.wv[w] for w in vocab_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then select only the N most common words as anchors to train our alignment. (If you're using the big model, this won't quite work because the vocabularies are different.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pickle.load(open('data/counts.pkl', 'rb'))\n",
    "n = 5000\n",
    "topN = [y for x,y in sorted([(counts[w], w) for w in w2idx if w in counts], reverse=True)][:n] #w2idx is from shared_vocab\n",
    "idxs = [w2idx[w] for w in topN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchorA = mtxA[idxs, :]\n",
    "anchorB = mtxB[idxs, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use two different techniques for aligning the embeddings: SVD and CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_svd(source, target):\n",
    "    product = np.matmul(source.transpose(), target)\n",
    "    U, s, V = np.linalg.svd(product)\n",
    "    T = np.matmul(U,V)\n",
    "    return T\n",
    "\n",
    "svd = align_svd(anchorA, anchorB)\n",
    "svdA = mtxA_.dot(svd)\n",
    "svdB = mtxB_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_cca(source, target):\n",
    "    N_dims = source.shape[1]\n",
    "    cca = CCA(n_components=N_dims, max_iter=2000)\n",
    "    cca.fit(source, target)\n",
    "    return cca\n",
    "\n",
    "cca = align_cca(anchorA, anchorB)\n",
    "ccaA, ccaB = cca.transform(mtxA, mtxB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_translator(a, b, a2idx, idx2b):\n",
    "    sims = cosine_similarity(a, b)\n",
    "    most_sims = np.argsort(sims, axis=1)[:, ::-1]\n",
    "    \n",
    "    def translator(w, k=1):\n",
    "        idx = a2idx[w]\n",
    "        idxs = most_sims[idx, :k]\n",
    "        words = [idx2b[i] for i in idxs]\n",
    "        return words, sims[idx, idxs]\n",
    "    \n",
    "    return translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = build_translator(svdA, svdB, a2idx, idx2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now explore three different ways of using the alignmed embeddings to explore the worldview and ideology of the two communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['democrat', 'republican', 'dem', 'democrats', 'republicans'],\n",
       " array([0.6164709 , 0.5891098 , 0.5137549 , 0.4719857 , 0.46580008],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator('democrat', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['lol', 'haha', 'yeah', ':face_with_tears_of_joy:', 'idk'],\n",
       " array([0.79610276, 0.7740769 , 0.7501412 , 0.74681777, 0.7448173 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MY DATASET\n",
    "translator('lol', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sex' in source_a (1 example sentence below):\n",
      "i have such a low sex drive that sometimes i suspect i 'm asexual or close to it . that 's basically persisted even when i was on a pretty intense exercise regimen and in good shape , so i do n't think that 's it . to date i still have n't really resolved that particular issue .\n",
      "\n",
      "translates to source_b words:\n",
      "\n",
      "('intimacy', 0.72380346)\n",
      "[\"for me ( 25 f ) , it 's not at the top of my list . i do find romance to be very important but intimacy does n't always have to include sex . my bf of 6 years on the other hand thinks that sex = love .\\n\"]\n",
      "\n",
      "('sex', 0.7049535)\n",
      "[\"yeah , i was in a sexually abusive relationship where he would do these things and i would let him , because i thought it was “ normal ” or how to be “ sexy , ” because that 's what they do in a lot of porn . now i can't / wo n't do any of those things due to trauma , and it makes me feel bad for my husband if he were ever to want to explore that .\\n\"]\n",
      "\n",
      "('pleasure', 0.6929905)\n",
      "['memory foam mattress , loads of small but firm pillows , a large blanket and a man who knows me , trusts me and who makes me feel fully comfortable to be naked and exposed around . a man who feels secure enough in himself to laugh in bed ( during sex ) and explore our bodies and pleasures .\\n']\n",
      "\n",
      "('intimate', 0.6702367)\n",
      "['definitely attraction , not necessarily emotional attachment . i think the willingness to listen and communicate likes / dislikes while being intimate is super important .\\n']\n",
      "\n",
      "('partner', 0.6552493)\n",
      "['working on your own insecurities will help . what are you unhappy with and what things can you improve on ? especially if its productive and provides you additional benefits . you can also ask your partner once in a while why they are with you . sometimes its nice to hear compliments from your partner and make sure you compliment them back . work on the aspects you are proud of . life is about work and small improvements . a good relationship should hopefully be about encouraging each other to do better and providing helpful feedback / opinions . no one is perfect , the best thing you can do is be the best person you can be and be confident .\\n']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function to get example sentences that contain said word\n",
    "def get_example_sentences(word, corpus, n_sentences):\n",
    "    sentences = random.sample([s for s in corpus if word in s], n_sentences)\n",
    "    return sentences\n",
    "\n",
    "n_sentences = 1\n",
    "\n",
    "word_a = 'sex'\n",
    "sentence_a = get_example_sentences(word_a, corpus_a, n_sentences)\n",
    "print('\\'{}\\' in source_a ({} example sentence below):'.format(word_a, n_sentences))\n",
    "[print(s) for s in sentence_a]\n",
    "\n",
    "word_b = translator(word_a, k=5)\n",
    "print('translates to source_b words:\\n')\n",
    "for w in zip(translator(word_a, k=5)[0], translator(word_a, k=5)[1]):\n",
    "    sentence_b = get_example_sentences(w[0], corpus_b, n_sentences)\n",
    "    print('{}\\n{}\\n'.format(w, [s for s in sentence_b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3664901664145234\n"
     ]
    }
   ],
   "source": [
    "misaligned = []\n",
    "scores = []\n",
    "\n",
    "for w in shared_vocab:\n",
    "    w_ = translator(w)[0][0]\n",
    "    s = translator(w)[1][0]\n",
    "    if w != w_:\n",
    "        misaligned.append((w, w_))\n",
    "        scores.append(s)\n",
    "        \n",
    "print(len(misaligned) / len(shared_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38506024096385544\n"
     ]
    }
   ],
   "source": [
    "# MY DATASET\n",
    "misaligned = []\n",
    "scores = []\n",
    "\n",
    "for w in shared_vocab:\n",
    "    w_ = translator(w)[0][0]\n",
    "    s = translator(w)[1][0]\n",
    "    if w != w_:\n",
    "        misaligned.append((w, w_))\n",
    "        scores.append(s)\n",
    "        \n",
    "print(len(misaligned) / len(shared_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('performed_automatically', 'please_contact') 0.8923226\n",
      "('moderators', 'please_contact') 0.8301286\n",
      "('``', \"''\") 0.7827312\n",
      "('&', 'gt') 0.74673975\n",
      "('bot', 'performed_automatically') 0.7402881\n",
      "(';', 'gt') 0.71963507\n",
      "('though', 'but') 0.7046928\n",
      "('citizenship_question', 'census') 0.68586487\n",
      "('amp', ';') 0.68398106\n",
      "('action', 'performed_automatically') 0.6676772\n",
      "('couple', 'few') 0.6567316\n",
      "('disagree', 'agree') 0.64628285\n",
      "('dems', 'democrats') 0.6362802\n",
      "('supreme_court', 'scotus') 0.61996275\n",
      "('republican', 'democrat') 0.6085014\n",
      "('dumb', 'stupid') 0.60647255\n",
      "('26_times', 'lolita_express') 0.6013237\n",
      "('capitalism', 'communism') 0.5988106\n",
      "('jeffrey_epstein', 'epstein') 0.59700453\n",
      "('illegal_immigrants', 'illegals') 0.5922674\n"
     ]
    }
   ],
   "source": [
    "for pair, score in sorted(zip(misaligned, scores), key=lambda x:x[1], reverse=True)[:20]:\n",
    "    print(pair, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('=/', 'compose') 0.93772894\n",
      "('automatically', 'compose') 0.9272409\n",
      "('performed', 'compose') 0.9270565\n",
      "('subreddit', 'compose') 0.91976225\n",
      "('bot', 'compose') 0.9151716\n",
      "('concerns', 'compose') 0.909357\n",
      "('moderators', 'compose') 0.9054626\n",
      "('[', ']') 0.8976162\n",
      "('action', 'compose') 0.89207244\n",
      "('message', 'performed') 0.87207484\n",
      "('shorts', 'pants') 0.86476004\n",
      "('sister', 'brother') 0.8642143\n",
      "('shirts', 'leggings') 0.8639887\n",
      "('please', 'compose') 0.85940146\n",
      "('cheap', 'buy') 0.85615104\n",
      "('food', 'meal') 0.8556203\n",
      "('6', '5') 0.854324\n",
      "('buying', 'buy') 0.85293144\n",
      "('r', 'compose') 0.85048825\n",
      "('play', 'games') 0.84840715\n"
     ]
    }
   ],
   "source": [
    "# MY DATASET\n",
    "for pair, score in sorted(zip(misaligned, scores), key=lambda x:x[1], reverse=True)[:20]:\n",
    "    print(pair, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2828/2828 [00:09<00:00, 310.07it/s] \n"
     ]
    }
   ],
   "source": [
    "def get_antonyms(vocab):\n",
    "    antonyms = []\n",
    "    for w in tqdm(vocab):\n",
    "        for synset in wordnet.synsets(w):\n",
    "            for lemma in synset.lemmas():\n",
    "                if lemma.antonyms():\n",
    "                    antonyms.append((w, lemma.antonyms()[0].name()))\n",
    "    antonyms = set(antonyms)\n",
    "    return antonyms\n",
    "\n",
    "antonyms = get_antonyms(combo_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('civilian', 'military')\n",
      "('decrease', 'increase')\n",
      "('disagree', 'agree')\n",
      "('disrespect', 'respect')\n",
      "('illogical', 'logical')\n",
      "('inaccurate', 'accurate')\n",
      "('indirectly', 'directly')\n",
      "('ineffective', 'effective')\n",
      "('intolerant', 'tolerant')\n",
      "('invalid', 'valid')\n",
      "('liability', 'asset')\n",
      "('sell', 'buy')\n",
      "('sells', 'buy')\n",
      "('unreasonable', 'reasonable')\n",
      "('unwilling', 'willing')\n",
      "('weakness', 'strength')\n",
      "('west', 'east')\n"
     ]
    }
   ],
   "source": [
    "for mPair in misaligned:\n",
    "    if mPair in antonyms or (mPair[0], mPair[1]) in antonyms:\n",
    "        print(mPair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('boy', 'girl')\n",
      "('disagree', 'agree')\n",
      "('expensive', 'cheap')\n",
      "('forward', 'back')\n",
      "('give', 'take')\n",
      "('light', 'dark')\n",
      "('male', 'female')\n",
      "('more', 'less')\n",
      "('particular', 'general')\n",
      "('positive', 'negative')\n",
      "('second', 'first')\n",
      "('sell', 'buy')\n",
      "('sister', 'brother')\n",
      "('small', 'big')\n",
      "('unfortunately', 'luckily')\n",
      "('white', 'black')\n",
      "('wife', 'husband')\n"
     ]
    }
   ],
   "source": [
    "# MY DATASET\n",
    "for mPair in misaligned:\n",
    "    if mPair in antonyms or (mPair[0], mPair[1]) in antonyms:\n",
    "        print(mPair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5847953216374269% misaligned pairs from 'misaligned', in 'antonyms' set\n"
     ]
    }
   ],
   "source": [
    "print(\"{}% misaligned pairs from 'misaligned', in 'antonyms' set\".format(len([mPair for mPair in misaligned if mPair in antonyms or (mPair[0], mPair[1]) in antonyms])/len(misaligned)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.127659574468085% misaligned pairs from 'misaligned', in 'antonyms' set\n"
     ]
    }
   ],
   "source": [
    "# MY DATASET\n",
    "print(\"{}% misaligned pairs from 'misaligned', in 'antonyms' set\".format(len([mPair for mPair in misaligned if mPair in antonyms or (mPair[0], mPair[1]) in antonyms])/len(misaligned)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation / Conceptual Homomorphisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vocab = []\n",
    "for w in model_a.wv.vocab:\n",
    "    if w not in model_b.wv.vocab:\n",
    "        unique_vocab.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "scores = []\n",
    "for w in unique_vocab:\n",
    "    t = translator(w)\n",
    "    translations.append((w, t[0][0]))\n",
    "    scores.append(t[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('instructions_provided', 'performed_automatically') 0.71877486\n",
      "('permanent_ban', 'performed_automatically') 0.69331694\n",
      "('rule_violations', 'performed_automatically') 0.63353837\n",
      "('wishing_death/physical', 'performed_automatically') 0.594555\n",
      "('fully_participate', 'please_contact') 0.5898004\n",
      "('rulebreaking_content', 'performed_automatically') 0.5775635\n",
      "('`_youtu.be', '`') 0.55210274\n",
      "('spam_domain', 'performed_automatically') 0.5434005\n",
      "('/r/politics_within', 'performed_automatically') 0.52550036\n",
      "('troll_accusations', 'performed_automatically') 0.51061064\n",
      "('whitelisting', 'performed_automatically') 0.4963802\n",
      "('blatant_spam', 'performed_automatically') 0.48971322\n",
      "('confederate_flag', 'flag') 0.48527563\n",
      "('excluding_indians', 'persons') 0.48497242\n",
      "('site_administrators', 'link_shortener') 0.48107997\n",
      "('following_reason', 'submission') 0.48058963\n",
      "('alan_dershowitz', 'epstein') 0.48009375\n",
      "('drinking_water', 'water') 0.47866067\n",
      "('breaking_channel', 'link_shortener') 0.47774062\n",
      "('nonreputable_/', 'performed_automatically') 0.47719014\n"
     ]
    }
   ],
   "source": [
    "for pair, score in sorted(zip(translations, scores), key=lambda x:x[1], reverse=True)[:20]:\n",
    "    print(pair, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('askmen', 'compose') 0.9154051\n",
      "askmen: [\"hi . we 've removed this post because reddit is not the place that you should go to for mental health counseling . we would highly recommend you seek out a therapist or speak with your primary care physician who can provide you with the correct resources . if those are not available to you , here 's some links that may help : [ rainn ] ( HTTPURL ) , [ nimh ] ( HTTPURL ) , [ uk stress support line ] ( HTTPURL ) , [ nhs mental health charity landing page ] ( HTTPURL ) , [ global health checkpoint landing page ] ( HTTPURL ) , [ global database for mental health lines for young people ] ( HTTPURL ) , [ vandrevala foundation india ] ( HTTPURL ) . if you have any questions or you feel like this post was flagged in error , please [ message the moderators ] ( HTTPURL ) . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n\"]\n",
      "compose: [\"your question has been removed because it is a frequently asked question or can be answered in one sentence and does not encourage conversation . please use the search bar or if you think it is n't , [ message the moderators ] ( HTTPURL ) with a link for approval . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n\"] \n",
      "\n",
      "('reasoning', 'compose') 0.8745596\n",
      "reasoning: ['your submission was removed by a computer . this could be for a number of reasons , most of which are summarized in the rules text on the right . in most of these cases , the computer is right , and we will not overturn its decision . if you have re-read your question and still think this is a failure of the automated filter , message us with an actual reason as to why the computer is wrong . if you just say that you think the computer is wrong without any reasoning , we will ignore you . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n']\n",
      "compose: ['the computer flagged this as a frequently asked question . use the search bar . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n'] \n",
      "\n",
      "('towel', 'wet') 0.8496522\n",
      "towel: [\"how the he 'll am i supposed to afford using a new towel every time i shower ? they 're not disposable . .\\n\"]\n",
      "wet: ['use water and soap to clean ur self instead of just wet wipes\\n'] \n",
      "\n",
      "('boots', 'pair') 0.83949333\n",
      "boots: [\"for my job , it 's when the boots come off . sincerely quasi-orgasmic .\\n\"]\n",
      "pair: [\"i have hanes , and they 're alright . but new balance boxer briefs , those are what i wear to workout and on dates . just ordered some pair of thieves that i got on sale , the cushioned socks are great and curious how their boxer briefs are\\n\"] \n",
      "\n",
      "('unattractive', 'attractive') 0.83702075\n",
      "unattractive: [\"yes and in the end i regretted shutting myself off from dating during my “ improvement period ” . it was just an excuse to not put myself out there . i was terrified of being rejected at first , and even more so after “ improving ” . when you are out of shape or have some excuse to not be at your best , being rejected is kind of expected and therefore not as painful . “ yeah she does n't like me now but that 's because i do n't have a 6 pack and biceps to fill out my t-shirt ” . well , what if i have those things and still get rejected ? that must mean there is something deeply unattractive about me that i can't possibly resolve , right ? those are the kind of gymnastics my brain did .\\n\"]\n",
      "attractive: [\"i actually started getting compliments . i 'm not ugly - somewhat attractive , but i do n't remember ever getting a random compliment in my life . it 's so bizarre to start getting them because of this . at about shoulder length i went on a date once and needed to adjust my hairband ( i usually just wear a ponytail so it may not appear as long ) . and she said something like “ wow your hair is so long and nice ” . at the time i blushed , said thanks and just assumed that she just happens to like long hair . but ever since it 's been happening consistently . and then i got in a relationship with a woman that jokingly ( but not really ) said that if i ever cut my hair she 'll break up with me .\\n\"] \n",
      "\n",
      "('yea', 'yeah') 0.8167581\n",
      "yea: [\"if you go to a street art fair that has those goofy rings you can always get her to try on as a joke . like put a ring on everyone one of your fingers and call it the infinity gauntlet and ask her to make hers . find out the ring size from there . existing rings if she wears them can be sized if she is a solid sleeper get ring sizers and test it out , but it will be ackward if she wakes up . ask her friend that you can trust to take her out under the pretense they are checking out rings . the friend can easily get the size out of her . chances are the friend will spoil it . any way rings can be resized . some places like blue nile have a ring size guarantee for up to a year and last but not least , the proposal event can be a surprise even if the ring is not . even if she finds out about the ring , she does n't know when where how etc . have fun and all the best to you\\n\"]\n",
      "yeah: [\"yeah there seems to be this notion that you 're supposed to “ evolve ” with your partner because that 's how a marriage work but no one really tells you that you 're not supposed to like the person your partner has become , everyone has their own needs in a relationship and standards for a partner and people are doing themselves a disservice by being with them out of social norms and just the fear of being alone .\\n\"] \n",
      "\n",
      "('taller', 'height') 0.8083593\n",
      "taller: ['> this can be about looks / appearance , personality-wise , etc . specific ones are what i \\'m curious about . no pale skin . no \" thickness \" . taller than average . athletic . professional or artistic in some way ( design , photography , food-related , etc ) . or an heiress ( philanthropic ) . intelligent , dry sense of humor .\\n']\n",
      "height: [\"wow ! that sounds straight out of a book . my boyfriend wants me to dominate him , and i do every now and then , but we work a lot and live in two different towns . i work in the town he lives and works in so its always me coming to see him , but usually we can't go to his house because he still lives with his mom so he does n't have to pay for dorms . i 'm getting an apartment in a few months so i should be able to do more then , but being in a car kind of makes it difficult for me . unless you have any ideas . i 'm 5 ' 6 and he is 5 ' 9 so not a crazy height difference and nothing too uncomfortable for a car\\n\"] \n",
      "\n",
      "('flagged', 'message') 0.80711895\n",
      "flagged: ['your post has been flagged as a commonly asked topic here ( relationship break-ups ) . if you think this action was made in error , [ message our moderators ] ( HTTPURL ) with a link to the post for approval . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n']\n",
      "message: ['your submission was removed by a computer . this could be for a number of reasons , most of which are summarized in the rules text on the right . in most of these cases , the computer is right , and we will not overturn its decision . if you have re-read your question and still think this is a failure of the automated filter , message us with an actual reason as to why the computer is wrong . if you just say that you think the computer is wrong without any reasoning , we will ignore you . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n'] \n",
      "\n",
      "('tongue', 'wet') 0.8066691\n",
      "tongue: ['you \\'re right , it does n\\'t have to be the sex specifically . for some it \\'s from being viewed and used as an object , a piece of meat all the time . the clients do n\\'t care about her as a person , they just want a living flesh light . for some the issues were there before they started prostituting themselves . in fact , the issues are why they went into prostitution . for some it \\'s the constant underlying fear of violence . just like soldiers , who live in constant fear of a mortar grenade falling down next to them , a prostitute can get ptsd from always being on edge when being fucked by strange men twice her size . and yes , for some , keeping it secret from friends and family can wear them out . but whatever the reason , dating a prostitute , former or current , is a can of worms few men want to open . i chatted with a prostitute a while back . she kept insisting that her past as a prostitute would n\\'t be a problem , because plenty of guys wanted to date her . the same with her friends . they had plenty of guys asking to be their boyfriends . i answered \" yes , but are these guys the kinds of men you would want to date ? not for money , but to have a relationship with , build a future and maybe have children with ? a guy you \\'re actually attracted to ? \" no , they were n\\'t . i think a lot of these girls see prostitution as quick and easy money without consequences . the one \\'s we hear about in this thread are the minority . most of them are dating or are married to guys who have no idea about their past . while they \\'re young , escorting seems like a great way to finance college , because the media speaks so positively about prostitution , escorting , sugar babes , onlyfans etc . they think there \\'s no problem because basically everyone does it . but then it happens . they meet him . the guy they thought they would n\\'t meet . the guy who sweeps them off their feet . \" i \\'ll tell him i was a sex worker in the second date . \" but the second date is amazing and she can\\'t bring herself to say it because she \\'s afraid there wo n\\'t be a third date . and she can\\'t bring herself to say it on the third , fourth or fifth date . i read about a guy finding out his wife was an escort in collage . her friend from those days had a slip of the tongue while drunk at dinner , so he started asking his wife questions . to say he was chocked was an understatement . he had always assumed that she was debt free because of her parents . in reality it was because she had fucked literally hundreds of men during her college years . and it was like i described above : she never thought of the long term consequences , because my body , my choice and all that - which is true by the way . but when she met the man of her dreams , she could n\\'t bring herself to tell him about that part of her college experience . the last thing he wrote about it was that he loved her and would stay with her . but she was extremely sad and distraught , because she knew something : the image of the the woman he married was forever changed . the way he looked at her , physically and metaphorically , would never be the same as before . oh , he still loved her and would stay with her , but the woman he married never existed . she knew that , and now he did too . what seemed like a great idea 15 years ago , seems less great now that the information is out .\\n']\n",
      "wet: [\"honestly i 'd say go to a place for a good haircut and just ask them what they 'd recommend . i got a good talk once about a volume powder to use along with other things . go somewhere decent and just get advice . i 've never given too much effort but one of my pals has a routine that involves a mousse applied while wet then blow dry with a curling brush or some shite , takes like half an hour . he 's also the most vain cunt i 've ever met though hahaha perfect time to try stuff out just now if you 're stuck at home !\\n\"] \n",
      "\n",
      "('weights', 'exercise') 0.8024705\n",
      "weights: ['i was a virgin when i was 27 . i was in the pits . i \\'m 33 now and have had some success . i \\'ve dated women i used to think i never had a chance with , had a couple relationships with real potential , and hooked up enough times that i stopped counting . i \\'m single now & happy now , but it used to eat me up inside , to feel undesired . here \\'s a few things i \\'ve learned along the way : * nobody \\'s going to help you besides yourself . this should n\\'t be depressing . it \\'s kinda like cheerful nihilism . you have all the power to make change in your own life * do n\\'t be afraid to take chances . it does n\\'t take a whole lot of suave say \" hey , do you want to get a coffee sometime ? \" 90 % of the time they \\'ll say no and you gotta roll with that . but 1/10 is betting odds ! * you are rejecting yourself more often than women * but also , it \\'s ok to take a break if dating is stressing you out * life is a lot easier when you \\'re attractive and have money . lift weights for a few years and cut down to 12 % ish fat . work on your resume . even a few hours a week on a new cert or skill will pay off eventually . i see so many guys complain how unfair this is .. that \\'s just life . you want to date successful , beautiful people , why should it be different for anyone else ? if you ever catch yourself thinking \" i just wish they \\'d give me a chance \" or \" i guess i \\'m not good enough \" , that \\'s pride talking , and pride does n\\'t get you anywhere . gear up and get better * learn sex stuff * just keep progressing , always have a goal , work on it consistently . if you find yourself watching tv & jerking off for a few weeks in a row , not working out , or not putting in ot at work , etc .. you gotta break that inertia idk jst a few thoughts ! i could ramble on forever but i feel like i \\'ve spoke too much already lol\\n']\n",
      "exercise: [\"because it reeks of the perspective of someone who simply has n't found any decent women yet when in reality there are tonnes . and instead of improving your vetting filters , you have resigned to accept it as some sort of inevitable reality of women . which ironically ensures that you 'll continue to run into the same type of unempathetic woman over n over again . it 's giving up out of ignorance , like a fat person giving up dieting and exercise because they can't figure out calories in / calories out . experience more people , figure out a way to vet against it .\\n\"] \n",
      "\n",
      "('automated', 'compose') 0.80003947\n",
      "automated: ['your submission was removed by a computer . this could be for a number of reasons , most of which are summarized in the rules text on the right . in most of these cases , the computer is right , and we will not overturn its decision . if you have re-read your question and still think this is a failure of the automated filter , message us with an actual reason as to why the computer is wrong . if you just say that you think the computer is wrong without any reasoning , we will ignore you . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n']\n",
      "compose: ['your question has been removed because it is asking about current events on the subreddit , all of which are explained in pinned mod posts on the frontpage . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n'] \n",
      "\n",
      "('pounds', 'weight') 0.7972007\n",
      "pounds: ['it felt like i could breathe more air . i just felt overall refreshed after cutting 30 pounds .\\n']\n",
      "weight: [\"i just thought about this today ! it 's really good response . however , it 's easier to change weight than height .\\n\"] \n",
      "\n",
      "('lifting', 'exercise') 0.7961578\n",
      "lifting: ['lifting weights\\n']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercise: [\"i went from being pretty much totally sedentary to exercising multiple times a week for the last several years . what clicked for me was just finding forms of exercise i enjoy doing - jogging , tennis , basketball , weightlifting , etc . some people like to swim , do cardio exercises , box , etc . - i 've tried to force myself to do those things but never sustained discipline simply because i did n't really enjoy them .\\n\"] \n",
      "\n",
      "('filter', 'compose') 0.79479\n",
      "filter: ['your submission was removed by a computer . this could be for a number of reasons , most of which are summarized in the rules text on the right . in most of these cases , the computer is right , and we will not overturn its decision . if you have re-read your question and still think this is a failure of the automated filter , message us with an actual reason as to why the computer is wrong . if you just say that you think the computer is wrong without any reasoning , we will ignore you . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n']\n",
      "compose: ['your submission was removed by a computer . this could be for a number of reasons , most of which are summarized in the rules text on the right . in most of these cases , the computer is right , and we will not overturn its decision . if you have re-read your question and still think this is a failure of the automated filter , message us with an actual reason as to why the computer is wrong . if you just say that you think the computer is wrong without any reasoning , we will ignore you . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n'] \n",
      "\n",
      "('re-read', 'compose') 0.78230286\n",
      "re-read: ['your submission was removed by a computer . this could be for a number of reasons , most of which are summarized in the rules text on the right . in most of these cases , the computer is right , and we will not overturn its decision . if you have re-read your question and still think this is a failure of the automated filter , message us with an actual reason as to why the computer is wrong . if you just say that you think the computer is wrong without any reasoning , we will ignore you . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n']\n",
      "compose: ['your submission was removed by a computer . this could be for a number of reasons , most of which are summarized in the rules text on the right . in most of these cases , the computer is right , and we will not overturn its decision . if you have re-read your question and still think this is a failure of the automated filter , message us with an actual reason as to why the computer is wrong . if you just say that you think the computer is wrong without any reasoning , we will ignore you . * i am a bot , and this action was performed automatically . please [ contact the moderators of this subreddit ] ( / message / compose / ? to =/ r / askmen ) if you have any questions or concerns . *\\n'] \n",
      "\n",
      "('muscles', 'muscle') 0.78025514\n",
      "muscles: [\"when i ever feel like i 'm about to be homeless or have no place to stay , i pretend that my skeleton is my body and my skin and muscles is my house . so , in a way , i 'm always at home , no matter where i 'm at .\\n\"]\n",
      "muscle: [\"i 'm a woman , so take what i say with a pinch of salt . but i 'm also a powerlifter . the only resistance training you 're doing is bodyweight press-ups , which honestly is n't much . train more muscle groups . do pull ups for a bigger back . do some press up variations to target different areas , ie diamond pushups to get your triceps . / r / bodyweightfitness for more ideas . like the other commenter said , make sure youre piling in the protein . each meal should have protein . change takes time . 1-2 weeks is absolutely nothing . consistency really , really is key . if you 're fat your gains wo n't show as much as some who is at a healthy weight .\\n\"] \n",
      "\n",
      "('bud', 'oh') 0.77917105\n",
      "bud: ['threesomes buddy , threesomes\\n']\n",
      "oh: ['the oh daddy and too much screaming ...\\n'] \n",
      "\n",
      "('dollars', '$') 0.77327776\n",
      "dollars: [\"yea but are n't canadian dollars just made out of american ham ?\\n\"]\n",
      "$: [\"i wear a $ 2 black silicone ring that i initially purchased for wearing at the gym . it 's so freaking comfy that the only time i take it off is to shower , cook , or work in the yard . on the other hand my brother had a silver ring custom-made for him . it looks cool , but not for what it cost him ( ~ $ 350 ) . there 's nothing wrong with the $ 100 ring . i wanted to just buy a $ 20 stainless steel ring for the wedding but the wife said no . i ended up with a titanium ring because it was the cheapest thing at the jewelers . these days that ring sits in a drawer .\\n\"] \n",
      "\n",
      "('trade', 'degree') 0.77315986\n",
      "trade: [\"oh i got the right degree . i am way above average salary for my nation . but it 's still shit compared to my salary aged 18 . and i had next to zero responsibilities and corporate bullshit . i turned up to the jobs , did the day , and got paid every week and i was my own boss self employed . now i am on payroll and have stupid meetings and loads of responsibility for less money , and 10 % extra student loan tax for my trouble . i would be vastly better off had i not gone to university . stop assuming everyone who regrets college got some 3rd class art degree . i did stem , i got headhunted by my current employer , they found me . trades still pay more if you are self employed and do a good job .\\n\"]\n",
      "degree: [\"save money , do n't beg for anyone 's attention and do n't sleep with just any random because you 're trying to find the right person . love who you are first . study harder , get a degree , travel\\n\"] \n",
      "\n",
      "('suit', 'dress') 0.766731\n",
      "suit: [\"i love cooking so would happily cool 5 time a week . cleaning does n't bother me but i fucking despise ironing . if i can find someone who like to iron but does n't like to cook then that would suit me perfectly\\n\"]\n",
      "dress: ['i live on coffee ! lol get up shower , get dressed and have a coffee . go to work have a coffee .. break coffee . afternoon break usually coffee . one after dinner and bed by 11 . get up n start over ! diet helps too i cut processed food and it made a huge difference .\\n'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MY DATASET\n",
    "for pair, score in sorted(zip(translations, scores), key=lambda x:x[1], reverse=True)[:20]:\n",
    "    print(pair, score)\n",
    "    print('{}: {}'.format(pair[0], get_example_sentences(pair[0], corpus_a, n_sentences)))\n",
    "    print('{}: {}'.format(pair[1], get_example_sentences(pair[1], corpus_a, n_sentences)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
